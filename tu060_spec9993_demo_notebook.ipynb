{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ocarrolj/ocarrolj.github.io/blob/main/tu060_spec9993_demo_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UfqLfnH2rym",
        "outputId": "9cd4daa2-6b02-4328-ac3d-6f384bb90317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 15 21:46:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    34W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5K2OlOhRBHG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pynvml\n",
        "%pip install matplotlib \n",
        "%pip install seaborn --upgrade\n",
        "%pip install matplotlib --upgrade\n",
        "%pip install tensorflow_text\n",
        "\n",
        "import pynvml\n",
        "import gdown\n",
        "import pynvml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run code\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "metadata": {
        "id": "MdcMhE7W9uOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fe2698-a398-4ea8-e65d-075b5d5dd777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH5yqINX7axb",
        "outputId": "c6097b40-3372-4963-e2f8-b8603e607f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "%cd \"/content\"\n",
        "!pwd\n",
        "%rm -rf TU060_SPEC9993"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm9GyV_nUf2x",
        "outputId": "100ae845-01e3-4b78-9b4c-f1f4b5dedd0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Cloning into 'TU060_SPEC9993'...\n",
            "remote: Enumerating objects: 947, done.\u001b[K\n",
            "remote: Counting objects: 100% (258/258), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 947 (delta 205), reused 192 (delta 140), pack-reused 689\u001b[K\n",
            "Receiving objects: 100% (947/947), 211.02 MiB | 46.31 MiB/s, done.\n",
            "Resolving deltas: 100% (661/661), done.\n"
          ]
        }
      ],
      "source": [
        "# Get Code\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "!git clone https://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:x-oauth-basic@github.com/ocarrolj/TU060_SPEC9993.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PTbAGnCnpqZ",
        "outputId": "c5e3738b-a355-4ae2-97f9-9df78493f038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TU060_SPEC9993/assignment\n",
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/            \u001b[01;34mdownloaded_embeddings\u001b[0m/      \u001b[01;34mpart_1\u001b[0m/\n",
            "\u001b[01;34mdatasets\u001b[0m/               \u001b[01;34mdownloaded_models\u001b[0m/          \u001b[01;34mpart_2\u001b[0m/\n",
            "dl_common_functions.py  part_0_data_preparation.py  \u001b[01;34mresults\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd ./TU060_SPEC9993/assignment\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLZ7SLiscLZU",
        "outputId": "61e9ba90-3a7c-4ee8-883f-9e7b567af1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 21:47:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-05-15 21:47:11--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-05-15 21:47:11--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.26MB/s    in 2m 40s  \n",
            "\n",
            "2022-05-15 21:49:51 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d ./downloaded_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvXFrlXJZVW",
        "outputId": "f70619ed-921f-4214-cfd4-e7ef99e98b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=194cBDBCmvkbjyG2LzTTdKsYarAIVz8E9\n",
            "To: /content/TU060_SPEC9993/assignment/archive.zip\n",
            "100% 108M/108M [00:00<00:00, 277MB/s]\n"
          ]
        }
      ],
      "source": [
        " # Get dataset\n",
        "!gdown 194cBDBCmvkbjyG2LzTTdKsYarAIVz8E9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZvMXjQ_OrnH",
        "outputId": "a6ea04e8-f0ff-4fa1-95e2-1acc12880f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive.zip\n",
            "replace ./datasets/kaggle_lyrics_dataset/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./datasets/kaggle_lyrics_dataset/test.csv  \n",
            "replace ./datasets/kaggle_lyrics_dataset/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./datasets/kaggle_lyrics_dataset/train.csv  y\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract dataset\n",
        "!mkdir -p ./datasets/kaggle_lyrics_dataset/\n",
        "!unzip archive.zip -d ./datasets/kaggle_lyrics_dataset/\n",
        "!mkdir -p ./figures\n",
        "!mkdir -p ./part_1/embedding_variants/saved_models/\n",
        "!mkdir -p ./part_1/cnn_variants/saved_models/\n",
        "!mkdir -p ./part_2/saved_models/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import zipfile\n",
        "saved_model_path = './downloaded_models/simply_the_best/'\n",
        "# **************************\n",
        "# Download Models\n",
        "# **************************\n",
        "saved_models_id = \"1EUG9ROhhjDCkDecG1FWJF0I2-HwtYOSQ\"\n",
        "#https://drive.google.com/file/d/1EUG9ROhhjDCkDecG1FWJF0I2-HwtYOSQ/view?usp=sharing\n",
        "\n",
        "gdown.download(id=saved_models_id, output=\"saved_models.zip\")\n",
        "\n",
        "with zipfile.ZipFile(\"saved_models.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2V20qHaLCrd",
        "outputId": "6575075c-fae1-4af6-9e19-2af227184d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EUG9ROhhjDCkDecG1FWJF0I2-HwtYOSQ\n",
            "To: /content/TU060_SPEC9993/assignment/saved_models.zip\n",
            "100%|██████████| 799M/799M [00:05<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pbyY5FILmQF",
        "outputId": "a7317661-fcad-4233-e0f4-5c9b7c791957"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:20:19:INFO:dl_project.part_1:<module>:--- 0.0008938312530517578 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 257962 rows in the dataset.\n",
            "There are 22766 duplicate songs in training dataset with the same lyrics and artist.\n",
            "There are 235196 rows in the deduplicated dataset.\n",
            "There are 160588 rows in the deduplicated where there are more than 50 songs by the artists\n",
            "Final combined shape (160588, 2)\n",
            "Number of rows in training set: 144529\n",
            "Number of rows in test set: 16059\n",
            "Artist class size: 1160\n",
            "New Artists found only in test dataset: 0\n",
            "Lyric b\"Carry on my wayward son\\nFor there'll be peace when you are done\\nLay your weary head to rest\\nDon't you cry no more\\n\\nOnce I rose above the noise and confusion\\nJust to get a glimpse beyond the illusion\\nI was soaring ever higher, but I flew too high\\nThough my eyes could see I still was a blind man\\nThough my mind could think I still was a mad man\\nI hear the voices when I'm dreamin', I can hear them say\\n\\nCarry on my wayward son\\nFor there'll be peace when you are done\\nLay your weary head to rest\\nDon't you cry no more\\n\\nMasquerading as a man with a reason\\nMy charade is the event of the season\\nAnd if I claim to be a wise man, it surely means that I don't know\\nOn a stormy sea of moving emotion\\nTossed about I'm like a ship on the ocean\\nI set a course for winds of fortune, but I hear the voices say\\n\\nCarry on my wayward son\\nFor there'll be peace when you are done\\nLay your weary head to rest\\nDon't you cry no more\\n\\nCarry on, you will always remember\\nCarry on, nothing equals the splendor\\nNow your life's no longer empty\\nSurely heaven waits for you\\n\\nCarry on my wayward son\\nFor there'll be peace when you are done\\nLay your weary head to rest\\nDon't you cry no more\"\n",
            "Artist Label 638\n",
            "Lyric b\"Howard beware 'cause we don't wanna hurt you\\nWhile the sun is shining, that'd be cruel\\nHoward beware 'cause we're gonna get you\\nWe know where your kids go to school\\n\\nHoward Howard beware\\nHoward Howard beware\\nHoward Howard beware\\nCause you're so easy to scare\\nYou'll hide from the shadows\\nAnd everybody knows\\n\\nHoward beware the Russians they don't like you\\nMight as well drop the bomb on you\\nHoward beware the government won't protect you\\nLike to see you turned into Howard stew\\n\\nHoward Howard beware\\nHoward Howard beware\\nHoward Howard beware\\nCause you're so easy to scare\\nYou'll hide from the shadows\\nAnd everybody knows\\n\\nHoward beware the neighbors wanna kill you\\nMight just all form an angry mob\\nHoward beware your mother has disowned you\\nSays that you're a pervert and a slob\\n\\nHoward Howard beware\\nHoward Howard beware\\nHoward Howard beware\\nCause you're so easy to scare\\nYou'll hide from the shadows\\nAnd everybody knows\\n\\n\\n\\n\"\n",
            "Artist Label 338\n",
            "Lyric b\"You'll never know how much I really love you\\nYou'll never know how much I really care\\nListen do you want to know a secret\\nDo you promise not to tell woh woh woh closer\\nLet me whisper in your ear\\nSay the words you long to hear\\nI'm in love with you oo\\nI've known the secret for a week or two\\nNobody knows just we two\\nListen do you want to know a secret\\nDo you promise not to tell woh woh woh closer\\nLet me whisper in your ear\\nSay the words you long to hear\\nI'm in love with you oo\"\n",
            "Artist Label 117\n",
            "Song tf.Tensor(b\"You look at me when we're here together\\nAnd I can hardly breathe\\nYour love hidden in your eyes\\nIs all I'll ever need\\nI'll give anything to know\\nIf you'd only let it show\\n\\n[Chorus]\\nIf you need my lose tonight\\nDon't be afraid just follow your heart\\nI'll be there\\nAnd your lonely nights are gone\\nIf you need my love tonight\\nDon't be afraid just follow your heart\\nI'll be there\\n\\nAnd your lonely nights are gone\\nLong gone\\n\\nSo many times I've waited in the shadows\\nFor you to come to me\\nTwo hearts hiding from the night\\nI need you here with me\\nI'd give you everything you know\\nIf you'd only let it show\\n\\n[Chorus: x2]\", shape=(), dtype=string)\n",
            "Artist ['aretha franklin']\n",
            "Vectorized song [[   3  127   69    8   34   75   82  264    5    4   39 1740  585   15\n",
            "    22 2112   11   15  131   19   17   73  136   87   73  103  376    6\n",
            "    25   42  458  106   66   10  191  135   42    3   87    9  328  160\n",
            "    23   18  538   30  520   15   92   73   18   79    5   15  326  588\n",
            "    54  149   42    3   87    9   22  160   23   18  538   30  520   15\n",
            "    92   73   18   79    5   15  326  588   54  149  129  149   24  306\n",
            "   304   89 1356   11    2  872   20    3    6   60    6    8  229  482\n",
            "  1326   64    2   93    4   87    3   82   29    8  193  103    3  164\n",
            "     3   25   42  458  106   66   10  191  135  773    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]] 60\n",
            "Vectorized song shape before and after () (1, 600)\n",
            "4 --->  i\n",
            "422 --->  white\n",
            "Vocabulary size: 20000\n",
            "Lyric b\"I turn the music up, I got my records on\\nI shut the world outside until the lights come on\\nMaybe the streets alight, maybe the trees are gone\\nI feel my heart start beating to my favourite song\\nAnd all the kids they dance, all the kids all night\\nUntil monday morning feels another life\\nI turn the music up\\nI'm on a roll this time\\nAnd heaven is in sight\\nI turn the music up, I got my records on\\nFrom underneath the rubble sing a rebel song\\nDon't want to see another generation drop\\nI'd rather be a comma than a full stop\\nMaybe I'm in the black, maybe I'm on my knees\\nMaybe I'm in the gap between the two trapezes\\nBut my heart is beating and my pulses start\\nCathedrals in my heart\\nAs we saw oh this light I swear you, emerge blinking into\\nTo tell me it's alright\\nAs we soar walls, every siren is a symphony\\nAnd every tear's a waterfall\\nIs a waterfall\\nOh\\nIs a waterfall\\nOh oh oh\\nIs a is a waterfall\\nEvery tear\\nIs a waterfall\\nOh oh oh\\nSo you can hurt, hurt me bad\\nBut still i'll raise the flag\\nOh\\nIt was a wa wa wa wa wa-aterfall\\nA wa wa wa wa wa-aterfall\\nEvery tear\\nEvery tear\\nEvery teardrop is a waterfall\\nEvery tear\\nEvery tear\\nEvery teardrop is a waterfall\\nEvery tear\\nEvery tear\\nEvery teardrop is a waterfall\\nEvery tear\\nEvery tear\\nEvery teardrop is a waterfall\"\n",
            "Genre Label 7\n",
            "Lyric b\"Woke up and had a face to face\\nGuess my reflection had a lot to say\\nWhy let my worries..\\nsteal my days\\nIt just brings me down\\nDoes the song you sing have enough meaning?\\nInspire us to sing along!\\nDoes the song you sing keep echoing?\\nInspire us to sing the song you sing\\nWhat's wrong with the world today?\\nTell me what's all the talk about?\\nLately I've been in a real bad place\\nCan't let the world\\nBring me down\\nDoes the song you sing have enough meaning?\\nInspire us to sing along!\\nDoes the song you sing keep echoing?\\nInspire us to sing the song you sing\\nI hope (I hope) the words I wrote (words I wrote)\\nKeep calling out (Keep calling out)\\nKeep Calling out...\\nForever (Forever)..\\nlet them sing (let them sing)\\nThat song you sing..\\nThat song you sing\\nI hope (I hope) the words I wrote (words I wrote)\\nKeep calling out..\\nKeep calling out...\\nForever (Forever)..\\nlet them ring (let them ring)\\nHear them echoing..\\nHear them echoing\\nDoes the song you sing have enough meaning?\\nInspire us to sing along!\\nDoes the song you sing keep echoing?\\nInspire us to sing the song you sing\\nThe song you sing?The song you sing\\nIt?s the song you sing\\nIt?s the life you bring\\nThat?s why I sing the song you sing\"\n",
            "Genre Label 9\n",
            "Lyric b'(when the fat man shaving in the Pullman washroom\\ngrunts, \"what\\'s this?\")\\nleave me on the moon\\nI must be coming back too soon\\npieces of pieces laying upon\\nsomebody\\'s walking on my hands\\nleave me on the moon\\neverybody knows it\\'s true\\neverything is good as long it\\'s stays still\\ncoins jingle in my brain\\nyou\\'ve been watching me\\nthrough your jewelry\\nsending rings around my hands\\nnow that I\\'m near you\\nI slowly disappear you\\nyour fingernails are much too long\\nleave me on the moon\\nyou can stay there too\\nseems like everybody\\'s just\\nfloating away\\nwhile I tie myself down.'\n",
            "Genre Label 7\n",
            "Song tf.Tensor(b\"When the day goes dark\\nObjects of the night\\nMirrors for the light\\nCall for me to come outside\\nAvenues with rain\\nA place to fade away\\nPhase into gold light\\nI'll fade, why can't I?\", shape=(), dtype=string)\n",
            "Genre ['Rock']\n",
            "Vectorized song [[   34     2    98   332   367 10808    12     2    95  3234    20     2\n",
            "    179   171    20     8     5    60   612 10787    29   300     7   204\n",
            "      5   702    83  3448   154   566   179    72   702   109    56     4\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0]] 9\n",
            "Vectorized song shape before and after () (1, 600)\n",
            "4 --->  i\n",
            "422 --->  couldnt\n",
            "Vocabulary size: 20000\n",
            "Song tf.Tensor(b\"It's the age-old conflict, the territorial dispute\\nEndless accusations flying about who has wronged who\\nDesperate determination to show no sign of weakness\\nThe leaders take action while their people pay the consequences\\nAbandoning diplomacy, those in power unwilling to yield\\nPlaying stupid fucking politics that just get people killed\\nDeciding that all out aggression is the best way to defend\\nso the cycle of violence starts all over again\\nIt's a bloodbath in the west bank\\nThere is no end in sight\\nBoth sides are so consumed with avenging death\\nthat there's no respect for life\\nIsraeli soldiers are gunning down Palestinians\\nMurdering children for throwing stones\\nWhile Hamas is recruiting children to become martyrs\\nand murder more Israelis as suicide bombers\\nBut the biggest obscenity of all of this hateful hostility\\nhas been reducing through action and rhetoric into a subhuman enemy\\nThe dehumanization of one another\\nhas been the justification for the horrific brutality\\nIt's a bloodbath in the Gaza strip\\nThere is no end in sight\\nBoth sides are so consumed with avenging death\\nthat there's no respect for life\\nHow many more?\\nHow long?\\nWho's right?\\nWho's wrong?\\nAre they really so bloodthirsty in their hatred for the enemy\\nthat they're willing to disregard their own peoples safety?\\nThey make their own people targets with every act of aggression\\nAll in the name of teaching the enemy a lesson\\nInnocent people imprisoned by the violence that the conflict creates\\nWarmongers and butchers deciding everyone's fate\\nHow will there ever be peace with such human rights abuses?\\nWhen you dehumanize humans then all humanity loses\\nIt's a bloodbath in Bethlehem\\nThere is no end in sight\\nBoth sides are so consumed with avenging death\\nthat there's no respect for life\", shape=(), dtype=string)\n",
            "Genre ['Rock']\n",
            "Vectorized song [[   27     2     1  7425     2     1     1  1417 11958  1001   104   117\n",
            "    214 13287   117  2282 10236     5   187    33   759    12  2710     2\n",
            "   4258    70  1618   238   221   200   513     2  5713 19050     1   271\n",
            "     11   587 14959     5  8016   646   953   617  4805    14    30    41\n",
            "    200  1413 11035    14    17    43  7973    19     2   270    67     5\n",
            "   3495    24     2  4459    12  2041   960    17   124   120    27     7\n",
            "  14103    11     2  1011  1635    82    19    33   208    11   745   531\n",
            "   2475    52    24  5507    29     1   529    14   107    33  1230    20\n",
            "     85     1  2019    52 10668    45     1 13776   661    20  2001  1793\n",
            "    238     1    19     1   661     5   779  9174     6  1188    96     1\n",
            "     76  1893 13809    28     2  2354     1    12    17    12    32  8272\n",
            "  14906   214    90     1   111  1618     6 19326   154     7     1  1384\n",
            "      2     1    12    47   191   214    90     2     1    20     2     1\n",
            "   9128    27     7 14103    11     2     1  1974    82    19    33   208\n",
            "     11   745   531  2475    52    24  5507    29     1   529    14   107\n",
            "     33  1230    20    85    75   309    96    75   131   493    80   493\n",
            "    210    52    54   155    24     1    11   221  2910    20     2  1384\n",
            "     14   351  1894     5  8086   221   230  3117  3551    54    68   221\n",
            "    230   200 11904    29   126   706    12  7973    17    11     2   225\n",
            "     12  6752     2  1384     7  1787  1690   200  9215    99     2  2041\n",
            "     14     2  7425  8526     1     6 13026 11035  1990   996    75    61\n",
            "     82   138    18   592    29   463   907  2846     1    34     3     1\n",
            "   5578   113    17  4188  7695    27     7 14103    11  4543    82    19\n",
            "     33   208    11   745   531  2475    52    24  5507    29     1   529\n",
            "     14   107    33  1230    20    85     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0]] 9\n",
            "Vectorized song shape before and after () (1, 600)\n",
            "4 --->  i\n",
            "422 --->  couldnt\n",
            "Vocabulary size: 20000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,120\n",
            "Trainable params: 5,418,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:21:55:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 OTF Embedding only and Global Average Pooling - Baseline\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,120\n",
            "Trainable params: 5,418,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.3985 - sparse_categorical_accuracy: 5.3472e-04\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 17s 13ms/step - loss: 7.3971 - sparse_categorical_accuracy: 5.3283e-04 - val_loss: 7.0541 - val_sparse_categorical_accuracy: 0.0015\n",
            "Epoch 2/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.0582 - sparse_categorical_accuracy: 5.2037e-04\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0582 - sparse_categorical_accuracy: 5.1899e-04 - val_loss: 7.0551 - val_sparse_categorical_accuracy: 0.0015\n",
            "Epoch 3/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0585 - sparse_categorical_accuracy: 4.4287e-04\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0585 - sparse_categorical_accuracy: 4.4287e-04 - val_loss: 7.0561 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 4/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.0590 - sparse_categorical_accuracy: 4.3672e-04\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0594 - sparse_categorical_accuracy: 4.3595e-04 - val_loss: 7.0580 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 5/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.0625 - sparse_categorical_accuracy: 5.4764e-04\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0629 - sparse_categorical_accuracy: 5.5359e-04 - val_loss: 7.0637 - val_sparse_categorical_accuracy: 0.0017\n",
            "Epoch 6/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.0704 - sparse_categorical_accuracy: 7.6389e-04\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0701 - sparse_categorical_accuracy: 7.6810e-04 - val_loss: 7.0726 - val_sparse_categorical_accuracy: 9.9206e-04\n",
            "Epoch 7/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.0784 - sparse_categorical_accuracy: 7.9719e-04\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0788 - sparse_categorical_accuracy: 8.0270e-04 - val_loss: 7.0822 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 8/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.0887 - sparse_categorical_accuracy: 7.7083e-04\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0885 - sparse_categorical_accuracy: 7.7502e-04 - val_loss: 7.0920 - val_sparse_categorical_accuracy: 0.0012\n",
            "Epoch 9/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.0974 - sparse_categorical_accuracy: 8.3804e-04\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.0978 - sparse_categorical_accuracy: 8.4422e-04 - val_loss: 7.1020 - val_sparse_categorical_accuracy: 0.0012\n",
            "Epoch 10/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1067 - sparse_categorical_accuracy: 8.3333e-04\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1064 - sparse_categorical_accuracy: 8.3730e-04 - val_loss: 7.1106 - val_sparse_categorical_accuracy: 0.0011\n",
            "Epoch 11/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1135 - sparse_categorical_accuracy: 9.1504e-04\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1139 - sparse_categorical_accuracy: 9.1342e-04 - val_loss: 7.1181 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 12/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1200 - sparse_categorical_accuracy: 8.9958e-04\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0012.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1200 - sparse_categorical_accuracy: 8.9958e-04 - val_loss: 7.1254 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 13/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1254 - sparse_categorical_accuracy: 0.0010\n",
            "Epoch 13: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0013.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1254 - sparse_categorical_accuracy: 0.0010 - val_loss: 7.1310 - val_sparse_categorical_accuracy: 0.0015\n",
            "Epoch 14/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1297 - sparse_categorical_accuracy: 0.0010\n",
            "Epoch 14: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0014.ckpt\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1297 - sparse_categorical_accuracy: 0.0011 - val_loss: 7.1363 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 15/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1329 - sparse_categorical_accuracy: 0.0011\n",
            "Epoch 15: saving model to ./checkpoints/transfer/P2 - M1 OTF Embedding only and Global Average Pooling - Baseline.kerascp-0015.ckpt\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "1129/1129 [==============================] - 14s 13ms/step - loss: 7.1332 - sparse_categorical_accuracy: 0.0011 - val_loss: 7.1395 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 15: early stopping\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:25:34:INFO:dl_project.part_1:classification_helper_transfer:Training time --- 219 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0636 - sparse_categorical_accuracy: 0.0019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:25:34:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "15-May-22 22:25:34:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 OTF Embedding only and Global Average Pooling - Baseline\n",
            "15-May-22 22:25:34:INFO:dl_project.part_1:classification_helper_transfer:test_loss: 7.06358 - test_accuracy: 0.00189\n",
            "15-May-22 22:25:34:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key                                                             \t  test_loss\t  test_accuracy\t  training_time\n",
            "P2 - M1 OTF Embedding only and Global Average Pooling - Baseline\t    7.06358\t     0.00189012\t            220\n",
            "############# Visualising Part 2 - Transfer Learning - P2 - M1 OTF Embedding only and Global Average Pooling - Baseline ###################\n",
            "############# output ./figures/Part 2 - Transfer Learning - P2 - M1 OTF Embedding only and Global Average Pooling - Baseline 2022_05_15-10_25_35_PM.png ###################\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.0636 - sparse_categorical_accuracy: 0.0019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:25:35:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 22:25:35:INFO:dl_project.part_1:<module>:P2 - M1 OTF Embedding only and Global Average Pooling - Baseline Reloaded\n",
            "15-May-22 22:25:35:INFO:dl_project.part_1:<module>:test_loss: 7.0636 - test_accuracy: 0.0019\n",
            "15-May-22 22:25:35:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 22:25:35:INFO:dl_project.part_1:<module>:Inference time --- 0 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "M1 Baseline OTF Embedding only and Global Average Pooling  - Model Evaluations\n",
            "_________________________________________________________________\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,122,570\n",
            "Trainable params: 5,122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 6.3556 - sparse_categorical_accuracy: 0.2335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:25:36:INFO:dl_project.part_1:get_part_1_model:_________________________________________________________________\n",
            "15-May-22 22:25:36:INFO:dl_project.part_1:get_part_1_model:M1 Baseline OTF Embedding only and Global Average Pooling  Reloaded\n",
            "15-May-22 22:25:36:INFO:dl_project.part_1:get_part_1_model:test_loss: 6.3556 - test_accuracy: 0.2335\n",
            "15-May-22 22:25:36:INFO:dl_project.part_1:get_part_1_model:_________________________________________________________________\n",
            "15-May-22 22:25:36:INFO:dl_project.part_1:get_part_1_model:Inference time --- 1 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,120\n",
            "Trainable params: 298,120\n",
            "Non-trainable params: 5,120,000\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:25:36:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 With TL Embedding Layer Only Base Frozen\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,120\n",
            "Trainable params: 298,120\n",
            "Non-trainable params: 5,120,000\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.4833 - sparse_categorical_accuracy: 6.7242e-04\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 6s 5ms/step - loss: 7.4831 - sparse_categorical_accuracy: 6.7122e-04 - val_loss: 7.1388 - val_sparse_categorical_accuracy: 9.9206e-04\n",
            "Epoch 2/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1431 - sparse_categorical_accuracy: 5.5506e-04\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1432 - sparse_categorical_accuracy: 5.5359e-04 - val_loss: 7.1418 - val_sparse_categorical_accuracy: 0.0011\n",
            "Epoch 3/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1441 - sparse_categorical_accuracy: 6.4469e-04\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1445 - sparse_categorical_accuracy: 6.4355e-04 - val_loss: 7.1427 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 4/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1449 - sparse_categorical_accuracy: 5.1343e-04\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1449 - sparse_categorical_accuracy: 5.1207e-04 - val_loss: 7.1434 - val_sparse_categorical_accuracy: 6.2004e-04\n",
            "Epoch 5/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1447 - sparse_categorical_accuracy: 6.3082e-04\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1450 - sparse_categorical_accuracy: 6.2971e-04 - val_loss: 7.1430 - val_sparse_categorical_accuracy: 6.2004e-04\n",
            "Epoch 6/300\n",
            "1124/1129 [============================>.] - ETA: 0s - loss: 7.1455 - sparse_categorical_accuracy: 5.2130e-04\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1451 - sparse_categorical_accuracy: 5.2591e-04 - val_loss: 7.1435 - val_sparse_categorical_accuracy: 6.2004e-04\n",
            "Epoch 7/300\n",
            "1122/1129 [============================>.] - ETA: 0s - loss: 7.1450 - sparse_categorical_accuracy: 5.9882e-04\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1450 - sparse_categorical_accuracy: 6.0203e-04 - val_loss: 7.1440 - val_sparse_categorical_accuracy: 7.4405e-04\n",
            "Epoch 8/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1451 - sparse_categorical_accuracy: 5.4812e-04\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1451 - sparse_categorical_accuracy: 5.4667e-04 - val_loss: 7.1437 - val_sparse_categorical_accuracy: 6.2004e-04\n",
            "Epoch 9/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1447 - sparse_categorical_accuracy: 5.6793e-04\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1451 - sparse_categorical_accuracy: 5.6743e-04 - val_loss: 7.1438 - val_sparse_categorical_accuracy: 4.9603e-04\n",
            "Epoch 10/300\n",
            "1121/1129 [============================>.] - ETA: 0s - loss: 7.1452 - sparse_categorical_accuracy: 5.7845e-04\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1450 - sparse_categorical_accuracy: 5.7435e-04 - val_loss: 7.1440 - val_sparse_categorical_accuracy: 9.9206e-04\n",
            "Epoch 11/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1451 - sparse_categorical_accuracy: 5.8819e-04\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1451 - sparse_categorical_accuracy: 5.8819e-04 - val_loss: 7.1442 - val_sparse_categorical_accuracy: 6.2004e-04\n",
            "Epoch 12/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1447 - sparse_categorical_accuracy: 5.8923e-04\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Base Frozen.kerascp-0012.ckpt\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "1129/1129 [==============================] - 5s 5ms/step - loss: 7.1451 - sparse_categorical_accuracy: 5.8819e-04 - val_loss: 7.1445 - val_sparse_categorical_accuracy: 4.9603e-04\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:26:40:INFO:dl_project.part_1:classification_helper_transfer:Training time --- 64 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1420 - sparse_categorical_accuracy: 0.0014\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:26:41:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "15-May-22 22:26:41:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 With TL Embedding Layer Only Base Frozen\n",
            "15-May-22 22:26:41:INFO:dl_project.part_1:classification_helper_transfer:test_loss: 7.142 - test_accuracy: 0.00139\n",
            "15-May-22 22:26:41:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key                                                             \t  test_loss\t  test_accuracy\t  training_time\n",
            "P2 - M1 OTF Embedding only and Global Average Pooling - Baseline\t    7.06358\t     0.00189012\t            220\n",
            "P2 - M1 With TL Embedding Layer Only Base Frozen                \t    7.142  \t     0.00138609\t             65\n",
            "############# Visualising Part 2 - Transfer Learning - P2 - M1 With TL Embedding Layer Only Base Frozen ###################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:26:41:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 With TL Embedding Layer Only Fine tuned\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############# output ./figures/Part 2 - Transfer Learning - P2 - M1 With TL Embedding Layer Only Base Frozen 2022_05_15-10_26_41_PM.png ###################\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 600, 256)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,418,120\n",
            "Trainable params: 5,418,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1376 - sparse_categorical_accuracy: 6.7122e-04\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 14s 12ms/step - loss: 7.1376 - sparse_categorical_accuracy: 6.7122e-04 - val_loss: 7.1339 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 2/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1365 - sparse_categorical_accuracy: 7.7709e-04\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1365 - sparse_categorical_accuracy: 7.7502e-04 - val_loss: 7.1341 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 3/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1363 - sparse_categorical_accuracy: 9.3667e-04\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1364 - sparse_categorical_accuracy: 9.4110e-04 - val_loss: 7.1363 - val_sparse_categorical_accuracy: 7.4405e-04\n",
            "Epoch 4/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1379 - sparse_categorical_accuracy: 9.0198e-04\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1379 - sparse_categorical_accuracy: 8.9958e-04 - val_loss: 7.1386 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 5/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1397 - sparse_categorical_accuracy: 8.7345e-04\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1401 - sparse_categorical_accuracy: 8.7882e-04 - val_loss: 7.1425 - val_sparse_categorical_accuracy: 9.9206e-04\n",
            "Epoch 6/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1426 - sparse_categorical_accuracy: 9.0650e-04\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1426 - sparse_categorical_accuracy: 9.0650e-04 - val_loss: 7.1455 - val_sparse_categorical_accuracy: 7.4405e-04\n",
            "Epoch 7/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1448 - sparse_categorical_accuracy: 0.0011\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1452 - sparse_categorical_accuracy: 0.0011 - val_loss: 7.1493 - val_sparse_categorical_accuracy: 4.9603e-04\n",
            "Epoch 8/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1472 - sparse_categorical_accuracy: 0.0010\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1476 - sparse_categorical_accuracy: 0.0010 - val_loss: 7.1524 - val_sparse_categorical_accuracy: 7.4405e-04\n",
            "Epoch 9/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1498 - sparse_categorical_accuracy: 0.0012\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1498 - sparse_categorical_accuracy: 0.0012 - val_loss: 7.1558 - val_sparse_categorical_accuracy: 8.6806e-04\n",
            "Epoch 10/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1519 - sparse_categorical_accuracy: 0.0011\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1517 - sparse_categorical_accuracy: 0.0011 - val_loss: 7.1584 - val_sparse_categorical_accuracy: 9.9206e-04\n",
            "Epoch 11/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1533 - sparse_categorical_accuracy: 0.0012\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1533 - sparse_categorical_accuracy: 0.0012 - val_loss: 7.1600 - val_sparse_categorical_accuracy: 0.0015\n",
            "Epoch 12/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1548 - sparse_categorical_accuracy: 0.0012\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0012.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1548 - sparse_categorical_accuracy: 0.0012 - val_loss: 7.1621 - val_sparse_categorical_accuracy: 0.0020\n",
            "Epoch 13/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1557 - sparse_categorical_accuracy: 0.0013\n",
            "Epoch 13: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0013.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1561 - sparse_categorical_accuracy: 0.0013 - val_loss: 7.1628 - val_sparse_categorical_accuracy: 0.0022\n",
            "Epoch 14/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1562 - sparse_categorical_accuracy: 0.0015\n",
            "Epoch 14: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0014.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1566 - sparse_categorical_accuracy: 0.0015 - val_loss: 7.1653 - val_sparse_categorical_accuracy: 0.0021\n",
            "Epoch 15/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1572 - sparse_categorical_accuracy: 0.0016\n",
            "Epoch 15: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0015.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1575 - sparse_categorical_accuracy: 0.0016 - val_loss: 7.1669 - val_sparse_categorical_accuracy: 0.0026\n",
            "Epoch 16/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1576 - sparse_categorical_accuracy: 0.0016\n",
            "Epoch 16: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0016.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1579 - sparse_categorical_accuracy: 0.0017 - val_loss: 7.1663 - val_sparse_categorical_accuracy: 0.0021\n",
            "Epoch 17/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1584 - sparse_categorical_accuracy: 0.0016\n",
            "Epoch 17: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0017.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1582 - sparse_categorical_accuracy: 0.0016 - val_loss: 7.1684 - val_sparse_categorical_accuracy: 0.0024\n",
            "Epoch 18/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1578 - sparse_categorical_accuracy: 0.0018\n",
            "Epoch 18: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0018.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1581 - sparse_categorical_accuracy: 0.0018 - val_loss: 7.1674 - val_sparse_categorical_accuracy: 0.0025\n",
            "Epoch 19/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1579 - sparse_categorical_accuracy: 0.0019\n",
            "Epoch 19: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0019.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1579 - sparse_categorical_accuracy: 0.0019 - val_loss: 7.1678 - val_sparse_categorical_accuracy: 0.0025\n",
            "Epoch 20/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1570 - sparse_categorical_accuracy: 0.0019\n",
            "Epoch 20: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0020.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1574 - sparse_categorical_accuracy: 0.0019 - val_loss: 7.1662 - val_sparse_categorical_accuracy: 0.0029\n",
            "Epoch 21/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1568 - sparse_categorical_accuracy: 0.0019\n",
            "Epoch 21: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0021.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1568 - sparse_categorical_accuracy: 0.0019 - val_loss: 7.1670 - val_sparse_categorical_accuracy: 0.0029\n",
            "Epoch 22/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1560 - sparse_categorical_accuracy: 0.0020\n",
            "Epoch 22: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0022.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1560 - sparse_categorical_accuracy: 0.0020 - val_loss: 7.1668 - val_sparse_categorical_accuracy: 0.0027\n",
            "Epoch 23/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1554 - sparse_categorical_accuracy: 0.0021\n",
            "Epoch 23: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0023.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1554 - sparse_categorical_accuracy: 0.0021 - val_loss: 7.1660 - val_sparse_categorical_accuracy: 0.0030\n",
            "Epoch 24/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1547 - sparse_categorical_accuracy: 0.0021\n",
            "Epoch 24: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0024.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1545 - sparse_categorical_accuracy: 0.0021 - val_loss: 7.1641 - val_sparse_categorical_accuracy: 0.0031\n",
            "Epoch 25/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1535 - sparse_categorical_accuracy: 0.0021\n",
            "Epoch 25: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0025.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1539 - sparse_categorical_accuracy: 0.0021 - val_loss: 7.1633 - val_sparse_categorical_accuracy: 0.0033\n",
            "Epoch 26/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1528 - sparse_categorical_accuracy: 0.0022\n",
            "Epoch 26: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0026.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1526 - sparse_categorical_accuracy: 0.0022 - val_loss: 7.1625 - val_sparse_categorical_accuracy: 0.0035\n",
            "Epoch 27/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1516 - sparse_categorical_accuracy: 0.0023\n",
            "Epoch 27: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0027.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1516 - sparse_categorical_accuracy: 0.0023 - val_loss: 7.1623 - val_sparse_categorical_accuracy: 0.0037\n",
            "Epoch 28/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1500 - sparse_categorical_accuracy: 0.0023\n",
            "Epoch 28: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0028.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1504 - sparse_categorical_accuracy: 0.0023 - val_loss: 7.1603 - val_sparse_categorical_accuracy: 0.0029\n",
            "Epoch 29/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1494 - sparse_categorical_accuracy: 0.0022\n",
            "Epoch 29: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0029.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1498 - sparse_categorical_accuracy: 0.0022 - val_loss: 7.1596 - val_sparse_categorical_accuracy: 0.0033\n",
            "Epoch 30/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1483 - sparse_categorical_accuracy: 0.0024\n",
            "Epoch 30: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0030.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1483 - sparse_categorical_accuracy: 0.0024 - val_loss: 7.1598 - val_sparse_categorical_accuracy: 0.0037\n",
            "Epoch 31/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1472 - sparse_categorical_accuracy: 0.0023\n",
            "Epoch 31: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0031.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1475 - sparse_categorical_accuracy: 0.0023 - val_loss: 7.1581 - val_sparse_categorical_accuracy: 0.0040\n",
            "Epoch 32/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1468 - sparse_categorical_accuracy: 0.0025\n",
            "Epoch 32: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0032.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1468 - sparse_categorical_accuracy: 0.0025 - val_loss: 7.1588 - val_sparse_categorical_accuracy: 0.0043\n",
            "Epoch 33/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1455 - sparse_categorical_accuracy: 0.0026\n",
            "Epoch 33: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0033.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1455 - sparse_categorical_accuracy: 0.0026 - val_loss: 7.1557 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 34/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1438 - sparse_categorical_accuracy: 0.0027\n",
            "Epoch 34: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0034.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1438 - sparse_categorical_accuracy: 0.0027 - val_loss: 7.1544 - val_sparse_categorical_accuracy: 0.0048\n",
            "Epoch 35/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1433 - sparse_categorical_accuracy: 0.0027\n",
            "Epoch 35: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0035.ckpt\n",
            "1129/1129 [==============================] - 14s 12ms/step - loss: 7.1433 - sparse_categorical_accuracy: 0.0027 - val_loss: 7.1538 - val_sparse_categorical_accuracy: 0.0038\n",
            "Epoch 36/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1419 - sparse_categorical_accuracy: 0.0026\n",
            "Epoch 36: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0036.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1422 - sparse_categorical_accuracy: 0.0027 - val_loss: 7.1546 - val_sparse_categorical_accuracy: 0.0042\n",
            "Epoch 37/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1413 - sparse_categorical_accuracy: 0.0027\n",
            "Epoch 37: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0037.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1410 - sparse_categorical_accuracy: 0.0027 - val_loss: 7.1547 - val_sparse_categorical_accuracy: 0.0042\n",
            "Epoch 38/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1404 - sparse_categorical_accuracy: 0.0029\n",
            "Epoch 38: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0038.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1402 - sparse_categorical_accuracy: 0.0029 - val_loss: 7.1514 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 39/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1393 - sparse_categorical_accuracy: 0.0030\n",
            "Epoch 39: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0039.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1393 - sparse_categorical_accuracy: 0.0030 - val_loss: 7.1518 - val_sparse_categorical_accuracy: 0.0036\n",
            "Epoch 40/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1380 - sparse_categorical_accuracy: 0.0029\n",
            "Epoch 40: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0040.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1383 - sparse_categorical_accuracy: 0.0029 - val_loss: 7.1481 - val_sparse_categorical_accuracy: 0.0046\n",
            "Epoch 41/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1368 - sparse_categorical_accuracy: 0.0029\n",
            "Epoch 41: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0041.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1371 - sparse_categorical_accuracy: 0.0029 - val_loss: 7.1480 - val_sparse_categorical_accuracy: 0.0050\n",
            "Epoch 42/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1359 - sparse_categorical_accuracy: 0.0029\n",
            "Epoch 42: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0042.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1359 - sparse_categorical_accuracy: 0.0029 - val_loss: 7.1472 - val_sparse_categorical_accuracy: 0.0046\n",
            "Epoch 43/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1355 - sparse_categorical_accuracy: 0.0031\n",
            "Epoch 43: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0043.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1353 - sparse_categorical_accuracy: 0.0031 - val_loss: 7.1487 - val_sparse_categorical_accuracy: 0.0042\n",
            "Epoch 44/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1341 - sparse_categorical_accuracy: 0.0031\n",
            "Epoch 44: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0044.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1341 - sparse_categorical_accuracy: 0.0031 - val_loss: 7.1489 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 45/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1328 - sparse_categorical_accuracy: 0.0031\n",
            "Epoch 45: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0045.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1332 - sparse_categorical_accuracy: 0.0031 - val_loss: 7.1448 - val_sparse_categorical_accuracy: 0.0041\n",
            "Epoch 46/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1318 - sparse_categorical_accuracy: 0.0032\n",
            "Epoch 46: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0046.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1322 - sparse_categorical_accuracy: 0.0032 - val_loss: 7.1443 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 47/300\n",
            "1126/1129 [============================>.] - ETA: 0s - loss: 7.1308 - sparse_categorical_accuracy: 0.0031\n",
            "Epoch 47: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0047.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1308 - sparse_categorical_accuracy: 0.0031 - val_loss: 7.1450 - val_sparse_categorical_accuracy: 0.0041\n",
            "Epoch 48/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 7.1292 - sparse_categorical_accuracy: 0.0034\n",
            "Epoch 48: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0048.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1296 - sparse_categorical_accuracy: 0.0034 - val_loss: 7.1458 - val_sparse_categorical_accuracy: 0.0040\n",
            "Epoch 49/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 7.1289 - sparse_categorical_accuracy: 0.0032\n",
            "Epoch 49: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0049.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1292 - sparse_categorical_accuracy: 0.0032 - val_loss: 7.1426 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 50/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.1279 - sparse_categorical_accuracy: 0.0032\n",
            "Epoch 50: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0050.ckpt\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1279 - sparse_categorical_accuracy: 0.0032 - val_loss: 7.1416 - val_sparse_categorical_accuracy: 0.0045\n",
            "Epoch 51/300\n",
            "1125/1129 [============================>.] - ETA: 0s - loss: 7.1272 - sparse_categorical_accuracy: 0.0033\n",
            "Epoch 51: saving model to ./checkpoints/transfer/P2 - M1 With TL Embedding Layer Only Fine tuned.kerascp-0051.ckpt\n",
            "Restoring model weights from the end of the best epoch: 41.\n",
            "1129/1129 [==============================] - 13s 12ms/step - loss: 7.1270 - sparse_categorical_accuracy: 0.0033 - val_loss: 7.1414 - val_sparse_categorical_accuracy: 0.0040\n",
            "Epoch 51: early stopping\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:38:02:INFO:dl_project.part_1:classification_helper_transfer:Training time --- 681 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1523 - sparse_categorical_accuracy: 0.0034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:38:03:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "15-May-22 22:38:03:INFO:dl_project.part_1:classification_helper_transfer:P2 - M1 With TL Embedding Layer Only Fine tuned\n",
            "15-May-22 22:38:03:INFO:dl_project.part_1:classification_helper_transfer:test_loss: 7.15226 - test_accuracy: 0.0034\n",
            "15-May-22 22:38:03:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key                                                             \t  test_loss\t  test_accuracy\t  training_time\n",
            "P2 - M1 OTF Embedding only and Global Average Pooling - Baseline\t    7.06358\t     0.00189012\t            220\n",
            "P2 - M1 With TL Embedding Layer Only Base Frozen                \t    7.142  \t     0.00138609\t             65\n",
            "P2 - M1 With TL Embedding Layer Only Fine tuned                 \t    7.15226\t     0.00340222\t            681\n",
            "############# Visualising Part 2 - Transfer Learning - P2 - M1 With TL Embedding Layer Only Fine tuned ###################\n",
            "############# output ./figures/Part 2 - Transfer Learning - P2 - M1 With TL Embedding Layer Only Fine tuned 2022_05_15-10_38_03_PM.png ###################\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 7.1523 - sparse_categorical_accuracy: 0.0034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:38:04:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 22:38:04:INFO:dl_project.part_1:<module>:P2 - M1 With TL Embedding Layer Only Reloaded\n",
            "15-May-22 22:38:04:INFO:dl_project.part_1:<module>:test_loss: 7.1523 - test_accuracy: 0.0034\n",
            "15-May-22 22:38:04:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 22:38:04:INFO:dl_project.part_1:<module>:Inference time --- 0 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,549,448\n",
            "Trainable params: 5,549,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 22:38:04:INFO:dl_project.part_1:classification_helper_transfer:P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,549,448\n",
            "Trainable params: 5,549,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.4102 - sparse_categorical_accuracy: 0.0012\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 31s 26ms/step - loss: 7.4102 - sparse_categorical_accuracy: 0.0012 - val_loss: 6.9888 - val_sparse_categorical_accuracy: 0.0067\n",
            "Epoch 2/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0294 - sparse_categorical_accuracy: 0.0031\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 7.0294 - sparse_categorical_accuracy: 0.0031 - val_loss: 6.9700 - val_sparse_categorical_accuracy: 0.0050\n",
            "Epoch 3/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0351 - sparse_categorical_accuracy: 0.0062\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 7.0351 - sparse_categorical_accuracy: 0.0062 - val_loss: 6.9466 - val_sparse_categorical_accuracy: 0.0081\n",
            "Epoch 4/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0100 - sparse_categorical_accuracy: 0.0103\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 7.0100 - sparse_categorical_accuracy: 0.0103 - val_loss: 6.8844 - val_sparse_categorical_accuracy: 0.0198\n",
            "Epoch 5/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.9643 - sparse_categorical_accuracy: 0.0149\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.9646 - sparse_categorical_accuracy: 0.0149 - val_loss: 6.8513 - val_sparse_categorical_accuracy: 0.0238\n",
            "Epoch 6/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.9281 - sparse_categorical_accuracy: 0.0202\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.9284 - sparse_categorical_accuracy: 0.0202 - val_loss: 6.8370 - val_sparse_categorical_accuracy: 0.0257\n",
            "Epoch 7/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8966 - sparse_categorical_accuracy: 0.0232\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.8966 - sparse_categorical_accuracy: 0.0232 - val_loss: 6.8298 - val_sparse_categorical_accuracy: 0.0293\n",
            "Epoch 8/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8695 - sparse_categorical_accuracy: 0.0262\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.8695 - sparse_categorical_accuracy: 0.0262 - val_loss: 6.8121 - val_sparse_categorical_accuracy: 0.0316\n",
            "Epoch 9/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8453 - sparse_categorical_accuracy: 0.0295\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.8453 - sparse_categorical_accuracy: 0.0295 - val_loss: 6.7940 - val_sparse_categorical_accuracy: 0.0368\n",
            "Epoch 10/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8225 - sparse_categorical_accuracy: 0.0325\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.8225 - sparse_categorical_accuracy: 0.0325 - val_loss: 6.7981 - val_sparse_categorical_accuracy: 0.0429\n",
            "Epoch 11/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7955 - sparse_categorical_accuracy: 0.0359\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.7955 - sparse_categorical_accuracy: 0.0359 - val_loss: 6.8052 - val_sparse_categorical_accuracy: 0.0404\n",
            "Epoch 12/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.7760 - sparse_categorical_accuracy: 0.0384\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0012.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.7764 - sparse_categorical_accuracy: 0.0383 - val_loss: 6.8071 - val_sparse_categorical_accuracy: 0.0439\n",
            "Epoch 13/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7552 - sparse_categorical_accuracy: 0.0411\n",
            "Epoch 13: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0013.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.7552 - sparse_categorical_accuracy: 0.0411 - val_loss: 6.8118 - val_sparse_categorical_accuracy: 0.0448\n",
            "Epoch 14/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.7336 - sparse_categorical_accuracy: 0.0437\n",
            "Epoch 14: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0014.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.7337 - sparse_categorical_accuracy: 0.0437 - val_loss: 6.8177 - val_sparse_categorical_accuracy: 0.0487\n",
            "Epoch 15/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7147 - sparse_categorical_accuracy: 0.0461\n",
            "Epoch 15: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0015.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.7147 - sparse_categorical_accuracy: 0.0461 - val_loss: 6.8234 - val_sparse_categorical_accuracy: 0.0503\n",
            "Epoch 16/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.6953 - sparse_categorical_accuracy: 0.0482\n",
            "Epoch 16: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0016.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.6956 - sparse_categorical_accuracy: 0.0482 - val_loss: 6.8305 - val_sparse_categorical_accuracy: 0.0497\n",
            "Epoch 17/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6729 - sparse_categorical_accuracy: 0.0507\n",
            "Epoch 17: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0017.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.6729 - sparse_categorical_accuracy: 0.0507 - val_loss: 6.8613 - val_sparse_categorical_accuracy: 0.0486\n",
            "Epoch 18/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6541 - sparse_categorical_accuracy: 0.0529\n",
            "Epoch 18: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0018.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.6541 - sparse_categorical_accuracy: 0.0529 - val_loss: 6.8537 - val_sparse_categorical_accuracy: 0.0517\n",
            "Epoch 19/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.6359 - sparse_categorical_accuracy: 0.0561\n",
            "Epoch 19: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0019.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.6362 - sparse_categorical_accuracy: 0.0561 - val_loss: 6.8662 - val_sparse_categorical_accuracy: 0.0527\n",
            "Epoch 20/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.6174 - sparse_categorical_accuracy: 0.0582\n",
            "Epoch 20: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0020.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.6176 - sparse_categorical_accuracy: 0.0582 - val_loss: 6.8621 - val_sparse_categorical_accuracy: 0.0564\n",
            "Epoch 21/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5962 - sparse_categorical_accuracy: 0.0615\n",
            "Epoch 21: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0021.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.5962 - sparse_categorical_accuracy: 0.0615 - val_loss: 6.8888 - val_sparse_categorical_accuracy: 0.0541\n",
            "Epoch 22/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.5806 - sparse_categorical_accuracy: 0.0627\n",
            "Epoch 22: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0022.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.5808 - sparse_categorical_accuracy: 0.0627 - val_loss: 6.8993 - val_sparse_categorical_accuracy: 0.0568\n",
            "Epoch 23/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5652 - sparse_categorical_accuracy: 0.0653\n",
            "Epoch 23: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0023.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.5652 - sparse_categorical_accuracy: 0.0653 - val_loss: 6.9144 - val_sparse_categorical_accuracy: 0.0583\n",
            "Epoch 24/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.5479 - sparse_categorical_accuracy: 0.0668\n",
            "Epoch 24: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0024.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.5479 - sparse_categorical_accuracy: 0.0668 - val_loss: 6.9187 - val_sparse_categorical_accuracy: 0.0623\n",
            "Epoch 25/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.5300 - sparse_categorical_accuracy: 0.0694\n",
            "Epoch 25: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0025.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.5302 - sparse_categorical_accuracy: 0.0694 - val_loss: 6.9270 - val_sparse_categorical_accuracy: 0.0604\n",
            "Epoch 26/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.5128 - sparse_categorical_accuracy: 0.0712\n",
            "Epoch 26: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0026.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.5130 - sparse_categorical_accuracy: 0.0711 - val_loss: 6.9323 - val_sparse_categorical_accuracy: 0.0616\n",
            "Epoch 27/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.4974 - sparse_categorical_accuracy: 0.0737\n",
            "Epoch 27: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0027.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.4976 - sparse_categorical_accuracy: 0.0737 - val_loss: 6.9434 - val_sparse_categorical_accuracy: 0.0619\n",
            "Epoch 28/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.4805 - sparse_categorical_accuracy: 0.0746\n",
            "Epoch 28: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0028.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.4807 - sparse_categorical_accuracy: 0.0746 - val_loss: 6.9516 - val_sparse_categorical_accuracy: 0.0626\n",
            "Epoch 29/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.4689 - sparse_categorical_accuracy: 0.0766\n",
            "Epoch 29: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0029.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.4690 - sparse_categorical_accuracy: 0.0766 - val_loss: 6.9742 - val_sparse_categorical_accuracy: 0.0608\n",
            "Epoch 30/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.4496 - sparse_categorical_accuracy: 0.0790\n",
            "Epoch 30: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0030.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.4498 - sparse_categorical_accuracy: 0.0790 - val_loss: 6.9692 - val_sparse_categorical_accuracy: 0.0655\n",
            "Epoch 31/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.4385 - sparse_categorical_accuracy: 0.0805\n",
            "Epoch 31: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0031.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.4388 - sparse_categorical_accuracy: 0.0805 - val_loss: 6.9823 - val_sparse_categorical_accuracy: 0.0632\n",
            "Epoch 32/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.4211 - sparse_categorical_accuracy: 0.0825\n",
            "Epoch 32: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0032.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.4211 - sparse_categorical_accuracy: 0.0825 - val_loss: 6.9813 - val_sparse_categorical_accuracy: 0.0642\n",
            "Epoch 33/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.4093 - sparse_categorical_accuracy: 0.0842\n",
            "Epoch 33: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0033.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.4093 - sparse_categorical_accuracy: 0.0842 - val_loss: 7.0094 - val_sparse_categorical_accuracy: 0.0656\n",
            "Epoch 34/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.3995 - sparse_categorical_accuracy: 0.0866\n",
            "Epoch 34: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0034.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3996 - sparse_categorical_accuracy: 0.0866 - val_loss: 7.0078 - val_sparse_categorical_accuracy: 0.0671\n",
            "Epoch 35/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.3842 - sparse_categorical_accuracy: 0.0880\n",
            "Epoch 35: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0035.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3842 - sparse_categorical_accuracy: 0.0880 - val_loss: 7.0479 - val_sparse_categorical_accuracy: 0.0629\n",
            "Epoch 36/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.3711 - sparse_categorical_accuracy: 0.0896\n",
            "Epoch 36: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0036.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3712 - sparse_categorical_accuracy: 0.0896 - val_loss: 7.0373 - val_sparse_categorical_accuracy: 0.0660\n",
            "Epoch 37/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.3539 - sparse_categorical_accuracy: 0.0917\n",
            "Epoch 37: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0037.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.3541 - sparse_categorical_accuracy: 0.0917 - val_loss: 7.0499 - val_sparse_categorical_accuracy: 0.0666\n",
            "Epoch 38/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.3447 - sparse_categorical_accuracy: 0.0935\n",
            "Epoch 38: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0038.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.3447 - sparse_categorical_accuracy: 0.0935 - val_loss: 7.0564 - val_sparse_categorical_accuracy: 0.0666\n",
            "Epoch 39/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.3307 - sparse_categorical_accuracy: 0.0946\n",
            "Epoch 39: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0039.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3307 - sparse_categorical_accuracy: 0.0946 - val_loss: 7.1042 - val_sparse_categorical_accuracy: 0.0635\n",
            "Epoch 40/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.3176 - sparse_categorical_accuracy: 0.0963\n",
            "Epoch 40: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0040.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3176 - sparse_categorical_accuracy: 0.0963 - val_loss: 7.0729 - val_sparse_categorical_accuracy: 0.0692\n",
            "Epoch 41/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.3078 - sparse_categorical_accuracy: 0.0979\n",
            "Epoch 41: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0041.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.3078 - sparse_categorical_accuracy: 0.0979 - val_loss: 7.0870 - val_sparse_categorical_accuracy: 0.0707\n",
            "Epoch 42/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2966 - sparse_categorical_accuracy: 0.0997\n",
            "Epoch 42: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0042.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.2968 - sparse_categorical_accuracy: 0.0996 - val_loss: 7.0961 - val_sparse_categorical_accuracy: 0.0703\n",
            "Epoch 43/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2788 - sparse_categorical_accuracy: 0.1022\n",
            "Epoch 43: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0043.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2791 - sparse_categorical_accuracy: 0.1022 - val_loss: 7.1221 - val_sparse_categorical_accuracy: 0.0672\n",
            "Epoch 44/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2743 - sparse_categorical_accuracy: 0.1025\n",
            "Epoch 44: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0044.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2744 - sparse_categorical_accuracy: 0.1024 - val_loss: 7.1184 - val_sparse_categorical_accuracy: 0.0687\n",
            "Epoch 45/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.2547 - sparse_categorical_accuracy: 0.1046\n",
            "Epoch 45: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0045.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.2547 - sparse_categorical_accuracy: 0.1046 - val_loss: 7.1356 - val_sparse_categorical_accuracy: 0.0702\n",
            "Epoch 46/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.2434 - sparse_categorical_accuracy: 0.1059\n",
            "Epoch 46: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0046.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2434 - sparse_categorical_accuracy: 0.1059 - val_loss: 7.1226 - val_sparse_categorical_accuracy: 0.0708\n",
            "Epoch 47/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2375 - sparse_categorical_accuracy: 0.1074\n",
            "Epoch 47: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0047.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2376 - sparse_categorical_accuracy: 0.1074 - val_loss: 7.1287 - val_sparse_categorical_accuracy: 0.0723\n",
            "Epoch 48/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2279 - sparse_categorical_accuracy: 0.1087\n",
            "Epoch 48: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0048.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2282 - sparse_categorical_accuracy: 0.1087 - val_loss: 7.1562 - val_sparse_categorical_accuracy: 0.0742\n",
            "Epoch 49/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2147 - sparse_categorical_accuracy: 0.1103\n",
            "Epoch 49: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0049.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.2148 - sparse_categorical_accuracy: 0.1103 - val_loss: 7.1281 - val_sparse_categorical_accuracy: 0.0734\n",
            "Epoch 50/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.2071 - sparse_categorical_accuracy: 0.1121\n",
            "Epoch 50: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0050.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.2072 - sparse_categorical_accuracy: 0.1121 - val_loss: 7.1575 - val_sparse_categorical_accuracy: 0.0738\n",
            "Epoch 51/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.1959 - sparse_categorical_accuracy: 0.1143\n",
            "Epoch 51: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0051.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1959 - sparse_categorical_accuracy: 0.1143 - val_loss: 7.1988 - val_sparse_categorical_accuracy: 0.0725\n",
            "Epoch 52/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.1852 - sparse_categorical_accuracy: 0.1152\n",
            "Epoch 52: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0052.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1853 - sparse_categorical_accuracy: 0.1153 - val_loss: 7.1857 - val_sparse_categorical_accuracy: 0.0728\n",
            "Epoch 53/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.1717 - sparse_categorical_accuracy: 0.1172\n",
            "Epoch 53: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0053.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1719 - sparse_categorical_accuracy: 0.1172 - val_loss: 7.2033 - val_sparse_categorical_accuracy: 0.0760\n",
            "Epoch 54/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.1675 - sparse_categorical_accuracy: 0.1182\n",
            "Epoch 54: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0054.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1678 - sparse_categorical_accuracy: 0.1182 - val_loss: 7.1894 - val_sparse_categorical_accuracy: 0.0734\n",
            "Epoch 55/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.1581 - sparse_categorical_accuracy: 0.1194\n",
            "Epoch 55: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0055.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.1585 - sparse_categorical_accuracy: 0.1194 - val_loss: 7.2360 - val_sparse_categorical_accuracy: 0.0724\n",
            "Epoch 56/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.1500 - sparse_categorical_accuracy: 0.1202\n",
            "Epoch 56: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0056.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.1501 - sparse_categorical_accuracy: 0.1202 - val_loss: 7.2569 - val_sparse_categorical_accuracy: 0.0707\n",
            "Epoch 57/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.1481 - sparse_categorical_accuracy: 0.1201\n",
            "Epoch 57: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0057.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1481 - sparse_categorical_accuracy: 0.1201 - val_loss: 7.2217 - val_sparse_categorical_accuracy: 0.0750\n",
            "Epoch 58/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.1303 - sparse_categorical_accuracy: 0.1237\n",
            "Epoch 58: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0058.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1304 - sparse_categorical_accuracy: 0.1237 - val_loss: 7.2215 - val_sparse_categorical_accuracy: 0.0761\n",
            "Epoch 59/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.1161 - sparse_categorical_accuracy: 0.1248\n",
            "Epoch 59: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0059.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1164 - sparse_categorical_accuracy: 0.1248 - val_loss: 7.2596 - val_sparse_categorical_accuracy: 0.0740\n",
            "Epoch 60/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.1146 - sparse_categorical_accuracy: 0.1252\n",
            "Epoch 60: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0060.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1146 - sparse_categorical_accuracy: 0.1252 - val_loss: 7.2887 - val_sparse_categorical_accuracy: 0.0732\n",
            "Epoch 61/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.1044 - sparse_categorical_accuracy: 0.1267\n",
            "Epoch 61: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0061.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.1044 - sparse_categorical_accuracy: 0.1267 - val_loss: 7.2729 - val_sparse_categorical_accuracy: 0.0760\n",
            "Epoch 62/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.0940 - sparse_categorical_accuracy: 0.1284\n",
            "Epoch 62: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0062.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0940 - sparse_categorical_accuracy: 0.1284 - val_loss: 7.2905 - val_sparse_categorical_accuracy: 0.0719\n",
            "Epoch 63/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.0784 - sparse_categorical_accuracy: 0.1305\n",
            "Epoch 63: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0063.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0783 - sparse_categorical_accuracy: 0.1305 - val_loss: 7.2530 - val_sparse_categorical_accuracy: 0.0786\n",
            "Epoch 64/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.0741 - sparse_categorical_accuracy: 0.1322\n",
            "Epoch 64: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0064.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0741 - sparse_categorical_accuracy: 0.1322 - val_loss: 7.3102 - val_sparse_categorical_accuracy: 0.0755\n",
            "Epoch 65/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.0727 - sparse_categorical_accuracy: 0.1312\n",
            "Epoch 65: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0065.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.0725 - sparse_categorical_accuracy: 0.1312 - val_loss: 7.3066 - val_sparse_categorical_accuracy: 0.0755\n",
            "Epoch 66/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.0590 - sparse_categorical_accuracy: 0.1336\n",
            "Epoch 66: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0066.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.0592 - sparse_categorical_accuracy: 0.1336 - val_loss: 7.3016 - val_sparse_categorical_accuracy: 0.0790\n",
            "Epoch 67/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.0588 - sparse_categorical_accuracy: 0.1338\n",
            "Epoch 67: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0067.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.0589 - sparse_categorical_accuracy: 0.1338 - val_loss: 7.2949 - val_sparse_categorical_accuracy: 0.0775\n",
            "Epoch 68/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.0461 - sparse_categorical_accuracy: 0.1362\n",
            "Epoch 68: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0068.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0463 - sparse_categorical_accuracy: 0.1362 - val_loss: 7.2833 - val_sparse_categorical_accuracy: 0.0786\n",
            "Epoch 69/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.0385 - sparse_categorical_accuracy: 0.1374\n",
            "Epoch 69: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0069.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0385 - sparse_categorical_accuracy: 0.1374 - val_loss: 7.3382 - val_sparse_categorical_accuracy: 0.0759\n",
            "Epoch 70/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.0258 - sparse_categorical_accuracy: 0.1380\n",
            "Epoch 70: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0070.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0258 - sparse_categorical_accuracy: 0.1380 - val_loss: 7.3452 - val_sparse_categorical_accuracy: 0.0780\n",
            "Epoch 71/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.0298 - sparse_categorical_accuracy: 0.1378\n",
            "Epoch 71: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0071.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 6.0298 - sparse_categorical_accuracy: 0.1378 - val_loss: 7.3092 - val_sparse_categorical_accuracy: 0.0807\n",
            "Epoch 72/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.0190 - sparse_categorical_accuracy: 0.1399\n",
            "Epoch 72: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0072.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0191 - sparse_categorical_accuracy: 0.1399 - val_loss: 7.3187 - val_sparse_categorical_accuracy: 0.0795\n",
            "Epoch 73/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 6.0075 - sparse_categorical_accuracy: 0.1410\n",
            "Epoch 73: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0073.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 6.0076 - sparse_categorical_accuracy: 0.1410 - val_loss: 7.3301 - val_sparse_categorical_accuracy: 0.0786\n",
            "Epoch 74/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9981 - sparse_categorical_accuracy: 0.1422\n",
            "Epoch 74: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0074.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9983 - sparse_categorical_accuracy: 0.1422 - val_loss: 7.4068 - val_sparse_categorical_accuracy: 0.0769\n",
            "Epoch 75/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9941 - sparse_categorical_accuracy: 0.1438\n",
            "Epoch 75: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0075.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9941 - sparse_categorical_accuracy: 0.1438 - val_loss: 7.3441 - val_sparse_categorical_accuracy: 0.0823\n",
            "Epoch 76/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9862 - sparse_categorical_accuracy: 0.1457\n",
            "Epoch 76: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0076.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9864 - sparse_categorical_accuracy: 0.1457 - val_loss: 7.3998 - val_sparse_categorical_accuracy: 0.0782\n",
            "Epoch 77/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9847 - sparse_categorical_accuracy: 0.1455\n",
            "Epoch 77: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0077.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9847 - sparse_categorical_accuracy: 0.1455 - val_loss: 7.4033 - val_sparse_categorical_accuracy: 0.0784\n",
            "Epoch 78/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9749 - sparse_categorical_accuracy: 0.1471\n",
            "Epoch 78: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0078.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9749 - sparse_categorical_accuracy: 0.1471 - val_loss: 7.3568 - val_sparse_categorical_accuracy: 0.0822\n",
            "Epoch 79/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9672 - sparse_categorical_accuracy: 0.1480\n",
            "Epoch 79: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0079.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9673 - sparse_categorical_accuracy: 0.1480 - val_loss: 7.3954 - val_sparse_categorical_accuracy: 0.0809\n",
            "Epoch 80/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 5.9708 - sparse_categorical_accuracy: 0.1477\n",
            "Epoch 80: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0080.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9711 - sparse_categorical_accuracy: 0.1476 - val_loss: 7.3479 - val_sparse_categorical_accuracy: 0.0846\n",
            "Epoch 81/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9488 - sparse_categorical_accuracy: 0.1497\n",
            "Epoch 81: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0081.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9488 - sparse_categorical_accuracy: 0.1497 - val_loss: 7.4210 - val_sparse_categorical_accuracy: 0.0804\n",
            "Epoch 82/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9479 - sparse_categorical_accuracy: 0.1504\n",
            "Epoch 82: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0082.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.9479 - sparse_categorical_accuracy: 0.1504 - val_loss: 7.3824 - val_sparse_categorical_accuracy: 0.0832\n",
            "Epoch 83/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9345 - sparse_categorical_accuracy: 0.1522\n",
            "Epoch 83: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0083.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9345 - sparse_categorical_accuracy: 0.1522 - val_loss: 7.4089 - val_sparse_categorical_accuracy: 0.0805\n",
            "Epoch 84/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9349 - sparse_categorical_accuracy: 0.1527\n",
            "Epoch 84: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0084.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9350 - sparse_categorical_accuracy: 0.1527 - val_loss: 7.4124 - val_sparse_categorical_accuracy: 0.0815\n",
            "Epoch 85/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9256 - sparse_categorical_accuracy: 0.1535\n",
            "Epoch 85: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0085.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.9259 - sparse_categorical_accuracy: 0.1534 - val_loss: 7.4374 - val_sparse_categorical_accuracy: 0.0795\n",
            "Epoch 86/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9276 - sparse_categorical_accuracy: 0.1536\n",
            "Epoch 86: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0086.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9276 - sparse_categorical_accuracy: 0.1536 - val_loss: 7.4423 - val_sparse_categorical_accuracy: 0.0815\n",
            "Epoch 87/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9234 - sparse_categorical_accuracy: 0.1551\n",
            "Epoch 87: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0087.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.9237 - sparse_categorical_accuracy: 0.1551 - val_loss: 7.4458 - val_sparse_categorical_accuracy: 0.0837\n",
            "Epoch 88/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.9112 - sparse_categorical_accuracy: 0.1565\n",
            "Epoch 88: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0088.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9113 - sparse_categorical_accuracy: 0.1566 - val_loss: 7.4251 - val_sparse_categorical_accuracy: 0.0848\n",
            "Epoch 89/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.9026 - sparse_categorical_accuracy: 0.1577\n",
            "Epoch 89: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0089.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.9026 - sparse_categorical_accuracy: 0.1577 - val_loss: 7.4351 - val_sparse_categorical_accuracy: 0.0884\n",
            "Epoch 90/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8987 - sparse_categorical_accuracy: 0.1572\n",
            "Epoch 90: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0090.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8987 - sparse_categorical_accuracy: 0.1572 - val_loss: 7.4376 - val_sparse_categorical_accuracy: 0.0852\n",
            "Epoch 91/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8985 - sparse_categorical_accuracy: 0.1591\n",
            "Epoch 91: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0091.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8989 - sparse_categorical_accuracy: 0.1591 - val_loss: 7.4378 - val_sparse_categorical_accuracy: 0.0841\n",
            "Epoch 92/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8843 - sparse_categorical_accuracy: 0.1597\n",
            "Epoch 92: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0092.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8845 - sparse_categorical_accuracy: 0.1597 - val_loss: 7.4811 - val_sparse_categorical_accuracy: 0.0838\n",
            "Epoch 93/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8853 - sparse_categorical_accuracy: 0.1595\n",
            "Epoch 93: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0093.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8853 - sparse_categorical_accuracy: 0.1595 - val_loss: 7.5523 - val_sparse_categorical_accuracy: 0.0800\n",
            "Epoch 94/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8797 - sparse_categorical_accuracy: 0.1606\n",
            "Epoch 94: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0094.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8797 - sparse_categorical_accuracy: 0.1606 - val_loss: 7.4385 - val_sparse_categorical_accuracy: 0.0887\n",
            "Epoch 95/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8695 - sparse_categorical_accuracy: 0.1623\n",
            "Epoch 95: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0095.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8695 - sparse_categorical_accuracy: 0.1623 - val_loss: 7.4748 - val_sparse_categorical_accuracy: 0.0889\n",
            "Epoch 96/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8685 - sparse_categorical_accuracy: 0.1626\n",
            "Epoch 96: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0096.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8687 - sparse_categorical_accuracy: 0.1627 - val_loss: 7.4244 - val_sparse_categorical_accuracy: 0.0854\n",
            "Epoch 97/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8597 - sparse_categorical_accuracy: 0.1633\n",
            "Epoch 97: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0097.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8600 - sparse_categorical_accuracy: 0.1633 - val_loss: 7.4231 - val_sparse_categorical_accuracy: 0.0889\n",
            "Epoch 98/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8473 - sparse_categorical_accuracy: 0.1641\n",
            "Epoch 98: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0098.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8475 - sparse_categorical_accuracy: 0.1641 - val_loss: 7.4652 - val_sparse_categorical_accuracy: 0.0877\n",
            "Epoch 99/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8465 - sparse_categorical_accuracy: 0.1652\n",
            "Epoch 99: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0099.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8465 - sparse_categorical_accuracy: 0.1652 - val_loss: 7.5037 - val_sparse_categorical_accuracy: 0.0869\n",
            "Epoch 100/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 5.8423 - sparse_categorical_accuracy: 0.1663\n",
            "Epoch 100: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0100.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8421 - sparse_categorical_accuracy: 0.1664 - val_loss: 7.4825 - val_sparse_categorical_accuracy: 0.0878\n",
            "Epoch 101/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 5.8450 - sparse_categorical_accuracy: 0.1666\n",
            "Epoch 101: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0101.ckpt\n",
            "1129/1129 [==============================] - 29s 26ms/step - loss: 5.8451 - sparse_categorical_accuracy: 0.1666 - val_loss: 7.5022 - val_sparse_categorical_accuracy: 0.0883\n",
            "Epoch 102/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8256 - sparse_categorical_accuracy: 0.1685\n",
            "Epoch 102: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0102.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8256 - sparse_categorical_accuracy: 0.1685 - val_loss: 7.4865 - val_sparse_categorical_accuracy: 0.0888\n",
            "Epoch 103/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8404 - sparse_categorical_accuracy: 0.1671\n",
            "Epoch 103: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0103.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8404 - sparse_categorical_accuracy: 0.1671 - val_loss: 7.5647 - val_sparse_categorical_accuracy: 0.0827\n",
            "Epoch 104/300\n",
            "1127/1129 [============================>.] - ETA: 0s - loss: 5.8240 - sparse_categorical_accuracy: 0.1691\n",
            "Epoch 104: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0104.ckpt\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8241 - sparse_categorical_accuracy: 0.1691 - val_loss: 7.5360 - val_sparse_categorical_accuracy: 0.0864\n",
            "Epoch 105/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 5.8143 - sparse_categorical_accuracy: 0.1704\n",
            "Epoch 105: saving model to ./checkpoints/transfer/P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling.kerascp-0105.ckpt\n",
            "Restoring model weights from the end of the best epoch: 95.\n",
            "1129/1129 [==============================] - 29s 25ms/step - loss: 5.8143 - sparse_categorical_accuracy: 0.1704 - val_loss: 7.5112 - val_sparse_categorical_accuracy: 0.0873\n",
            "Epoch 105: early stopping\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:28:33:INFO:dl_project.part_1:classification_helper_transfer:Training time --- 3029 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 6ms/step - loss: 7.4364 - sparse_categorical_accuracy: 0.0859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:28:34:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "15-May-22 23:28:34:INFO:dl_project.part_1:classification_helper_transfer:P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling\n",
            "15-May-22 23:28:34:INFO:dl_project.part_1:classification_helper_transfer:test_loss: 7.43644 - test_accuracy: 0.08594\n",
            "15-May-22 23:28:34:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key                                                                     \t  test_loss\t  test_accuracy\t  training_time\n",
            "P2 - M1 OTF Embedding only and Global Average Pooling - Baseline        \t    7.06358\t     0.00189012\t            220\n",
            "P2 - M1 With TL Embedding Layer Only Base Frozen                        \t    7.142  \t     0.00138609\t             65\n",
            "P2 - M1 With TL Embedding Layer Only Fine tuned                         \t    7.15226\t     0.00340222\t            681\n",
            "P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling\t    7.43644\t     0.0859375 \t           3030\n",
            "############# Visualising Part 2 - Transfer Learning - P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling ###################\n",
            "############# output ./figures/Part 2 - Transfer Learning - P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling 2022_05_15-11_28_34_PM.png ###################\n",
            "62/62 [==============================] - 1s 6ms/step - loss: 7.4364 - sparse_categorical_accuracy: 0.0859\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:28:35:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 23:28:35:INFO:dl_project.part_1:<module>:P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling Reloaded\n",
            "15-May-22 23:28:35:INFO:dl_project.part_1:<module>:test_loss: 7.4364 - test_accuracy: 0.0859\n",
            "15-May-22 23:28:35:INFO:dl_project.part_1:<module>:_________________________________________________________________\n",
            "15-May-22 23:28:35:INFO:dl_project.part_1:<module>:Inference time --- 1 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "M3 OTF Embedding - CNN 1 channel - homogeneous kernel sizes - Baseline - Model Evaluations\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,253,898\n",
            "Trainable params: 5,253,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "61/61 [==============================] - 1s 6ms/step - loss: 14.1590 - sparse_categorical_accuracy: 0.1642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:28:36:INFO:dl_project.part_1:get_part_1_model:_________________________________________________________________\n",
            "15-May-22 23:28:36:INFO:dl_project.part_1:get_part_1_model:M3 OTF Embedding - CNN 1 channel - homogeneous kernel sizes - Baseline Reloaded\n",
            "15-May-22 23:28:36:INFO:dl_project.part_1:get_part_1_model:test_loss: 14.159 - test_accuracy: 0.1642\n",
            "15-May-22 23:28:36:INFO:dl_project.part_1:get_part_1_model:_________________________________________________________________\n",
            "15-May-22 23:28:36:INFO:dl_project.part_1:get_part_1_model:Inference time --- 1 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,549,448\n",
            "Trainable params: 298,120\n",
            "Non-trainable params: 5,251,328\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:28:36:INFO:dl_project.part_1:classification_helper_transfer:P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,549,448\n",
            "Trainable params: 298,120\n",
            "Non-trainable params: 5,251,328\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 11.0572 - sparse_categorical_accuracy: 8.3730e-04\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 9s 7ms/step - loss: 11.0572 - sparse_categorical_accuracy: 8.3730e-04 - val_loss: 8.5074 - val_sparse_categorical_accuracy: 0.0014\n",
            "Epoch 2/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1858 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1858 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.5551 - val_sparse_categorical_accuracy: 0.0022\n",
            "Epoch 3/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 9.1862 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1868 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.5342 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 4/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1768 - sparse_categorical_accuracy: 0.0013\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1768 - sparse_categorical_accuracy: 0.0013 - val_loss: 8.5111 - val_sparse_categorical_accuracy: 0.0012\n",
            "Epoch 5/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1787 - sparse_categorical_accuracy: 0.0013\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1787 - sparse_categorical_accuracy: 0.0013 - val_loss: 8.5046 - val_sparse_categorical_accuracy: 0.0019\n",
            "Epoch 6/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1702 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1702 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.4943 - val_sparse_categorical_accuracy: 0.0019\n",
            "Epoch 7/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1705 - sparse_categorical_accuracy: 0.0015\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1705 - sparse_categorical_accuracy: 0.0015 - val_loss: 8.5330 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 8/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1598 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1598 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.5019 - val_sparse_categorical_accuracy: 0.0019\n",
            "Epoch 9/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1565 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1565 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.4540 - val_sparse_categorical_accuracy: 0.0020\n",
            "Epoch 10/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1491 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1491 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.4772 - val_sparse_categorical_accuracy: 0.0016\n",
            "Epoch 11/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1492 - sparse_categorical_accuracy: 0.0014\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1492 - sparse_categorical_accuracy: 0.0014 - val_loss: 8.4786 - val_sparse_categorical_accuracy: 0.0022\n",
            "Epoch 12/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 9.1529 - sparse_categorical_accuracy: 0.0015\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen.kerascp-0012.ckpt\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "1129/1129 [==============================] - 8s 7ms/step - loss: 9.1529 - sparse_categorical_accuracy: 0.0015 - val_loss: 8.4822 - val_sparse_categorical_accuracy: 0.0020\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:30:12:INFO:dl_project.part_1:classification_helper_transfer:Training time --- 97 seconds ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 6ms/step - loss: 8.5427 - sparse_categorical_accuracy: 0.0016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:30:13:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "15-May-22 23:30:13:INFO:dl_project.part_1:classification_helper_transfer:P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen\n",
            "15-May-22 23:30:13:INFO:dl_project.part_1:classification_helper_transfer:test_loss: 8.54268 - test_accuracy: 0.00164\n",
            "15-May-22 23:30:13:INFO:dl_project.part_1:classification_helper_transfer:_________________________________________________________________\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key                                                                     \t  test_loss\t  test_accuracy\t  training_time\n",
            "P2 - M1 OTF Embedding only and Global Average Pooling - Baseline        \t    7.06358\t     0.00189012\t            220\n",
            "P2 - M1 With TL Embedding Layer Only Base Frozen                        \t    7.142  \t     0.00138609\t             65\n",
            "P2 - M1 With TL Embedding Layer Only Fine tuned                         \t    7.15226\t     0.00340222\t            681\n",
            "P2 - M2 CNN (2,256) - 1 Channel - OTF Embedding - Global Average Pooling\t    7.43644\t     0.0859375 \t           3030\n",
            "P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen   \t    8.54268\t     0.0016381 \t             97\n",
            "############# Visualising Part 2 - Transfer Learning - P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen ###################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15-May-22 23:30:13:INFO:dl_project.part_1:classification_helper_transfer:P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# output ./figures/Part 2 - Transfer Learning - P2 - M2 with TL , Embedding, Conv1D and Global Max layers Base Frozen 2022_05_15-11_30_13_PM.png ###################\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 600, 256)          5120000   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 599, 256)          131328    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1160)              298120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,549,448\n",
            "Trainable params: 5,549,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Checkpoint path: ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-{epoch:04d}.ckpt\n",
            "Epoch 1/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.6827 - sparse_categorical_accuracy: 0.0077\n",
            "Epoch 1: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0001.ckpt\n",
            "1129/1129 [==============================] - 31s 26ms/step - loss: 7.6827 - sparse_categorical_accuracy: 0.0077 - val_loss: 7.0848 - val_sparse_categorical_accuracy: 0.0201\n",
            "Epoch 2/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0919 - sparse_categorical_accuracy: 0.0212\n",
            "Epoch 2: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0002.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 7.0919 - sparse_categorical_accuracy: 0.0212 - val_loss: 6.9974 - val_sparse_categorical_accuracy: 0.0334\n",
            "Epoch 3/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0507 - sparse_categorical_accuracy: 0.0307\n",
            "Epoch 3: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0003.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 7.0507 - sparse_categorical_accuracy: 0.0307 - val_loss: 6.9869 - val_sparse_categorical_accuracy: 0.0401\n",
            "Epoch 4/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 7.0270 - sparse_categorical_accuracy: 0.0356\n",
            "Epoch 4: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0004.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 7.0270 - sparse_categorical_accuracy: 0.0356 - val_loss: 6.9914 - val_sparse_categorical_accuracy: 0.0434\n",
            "Epoch 5/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.9992 - sparse_categorical_accuracy: 0.0398\n",
            "Epoch 5: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0005.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.9992 - sparse_categorical_accuracy: 0.0398 - val_loss: 6.9935 - val_sparse_categorical_accuracy: 0.0476\n",
            "Epoch 6/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.9742 - sparse_categorical_accuracy: 0.0439\n",
            "Epoch 6: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0006.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.9742 - sparse_categorical_accuracy: 0.0439 - val_loss: 7.0034 - val_sparse_categorical_accuracy: 0.0494\n",
            "Epoch 7/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.9515 - sparse_categorical_accuracy: 0.0470\n",
            "Epoch 7: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0007.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.9515 - sparse_categorical_accuracy: 0.0470 - val_loss: 7.0103 - val_sparse_categorical_accuracy: 0.0510\n",
            "Epoch 8/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.9235 - sparse_categorical_accuracy: 0.0499\n",
            "Epoch 8: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0008.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.9235 - sparse_categorical_accuracy: 0.0499 - val_loss: 7.0042 - val_sparse_categorical_accuracy: 0.0516\n",
            "Epoch 9/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8951 - sparse_categorical_accuracy: 0.0529\n",
            "Epoch 9: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0009.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.8951 - sparse_categorical_accuracy: 0.0529 - val_loss: 7.0022 - val_sparse_categorical_accuracy: 0.0557\n",
            "Epoch 10/300\n",
            "1128/1129 [============================>.] - ETA: 0s - loss: 6.8663 - sparse_categorical_accuracy: 0.0555\n",
            "Epoch 10: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0010.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.8666 - sparse_categorical_accuracy: 0.0555 - val_loss: 7.0149 - val_sparse_categorical_accuracy: 0.0548\n",
            "Epoch 11/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8433 - sparse_categorical_accuracy: 0.0587\n",
            "Epoch 11: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0011.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.8433 - sparse_categorical_accuracy: 0.0587 - val_loss: 7.0126 - val_sparse_categorical_accuracy: 0.0572\n",
            "Epoch 12/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.8164 - sparse_categorical_accuracy: 0.0616\n",
            "Epoch 12: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0012.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.8164 - sparse_categorical_accuracy: 0.0616 - val_loss: 7.0330 - val_sparse_categorical_accuracy: 0.0565\n",
            "Epoch 13/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7904 - sparse_categorical_accuracy: 0.0645\n",
            "Epoch 13: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0013.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.7904 - sparse_categorical_accuracy: 0.0645 - val_loss: 7.0338 - val_sparse_categorical_accuracy: 0.0570\n",
            "Epoch 14/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7644 - sparse_categorical_accuracy: 0.0663\n",
            "Epoch 14: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0014.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.7644 - sparse_categorical_accuracy: 0.0663 - val_loss: 7.0288 - val_sparse_categorical_accuracy: 0.0592\n",
            "Epoch 15/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7425 - sparse_categorical_accuracy: 0.0687\n",
            "Epoch 15: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0015.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.7425 - sparse_categorical_accuracy: 0.0687 - val_loss: 7.0378 - val_sparse_categorical_accuracy: 0.0579\n",
            "Epoch 16/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7230 - sparse_categorical_accuracy: 0.0708\n",
            "Epoch 16: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0016.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.7230 - sparse_categorical_accuracy: 0.0708 - val_loss: 7.0450 - val_sparse_categorical_accuracy: 0.0595\n",
            "Epoch 17/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.7010 - sparse_categorical_accuracy: 0.0736\n",
            "Epoch 17: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0017.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.7010 - sparse_categorical_accuracy: 0.0736 - val_loss: 7.0609 - val_sparse_categorical_accuracy: 0.0592\n",
            "Epoch 18/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6791 - sparse_categorical_accuracy: 0.0751\n",
            "Epoch 18: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0018.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.6791 - sparse_categorical_accuracy: 0.0751 - val_loss: 7.0721 - val_sparse_categorical_accuracy: 0.0611\n",
            "Epoch 19/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6583 - sparse_categorical_accuracy: 0.0773\n",
            "Epoch 19: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0019.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.6583 - sparse_categorical_accuracy: 0.0773 - val_loss: 7.0625 - val_sparse_categorical_accuracy: 0.0618\n",
            "Epoch 20/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6380 - sparse_categorical_accuracy: 0.0784\n",
            "Epoch 20: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0020.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.6380 - sparse_categorical_accuracy: 0.0784 - val_loss: 7.0564 - val_sparse_categorical_accuracy: 0.0632\n",
            "Epoch 21/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.6148 - sparse_categorical_accuracy: 0.0807\n",
            "Epoch 21: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0021.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.6148 - sparse_categorical_accuracy: 0.0807 - val_loss: 7.0763 - val_sparse_categorical_accuracy: 0.0649\n",
            "Epoch 22/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5930 - sparse_categorical_accuracy: 0.0842\n",
            "Epoch 22: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0022.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5930 - sparse_categorical_accuracy: 0.0842 - val_loss: 7.0651 - val_sparse_categorical_accuracy: 0.0627\n",
            "Epoch 23/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5768 - sparse_categorical_accuracy: 0.0848\n",
            "Epoch 23: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0023.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5768 - sparse_categorical_accuracy: 0.0848 - val_loss: 7.0800 - val_sparse_categorical_accuracy: 0.0639\n",
            "Epoch 24/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5636 - sparse_categorical_accuracy: 0.0861\n",
            "Epoch 24: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0024.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5636 - sparse_categorical_accuracy: 0.0861 - val_loss: 7.0989 - val_sparse_categorical_accuracy: 0.0661\n",
            "Epoch 25/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5426 - sparse_categorical_accuracy: 0.0877\n",
            "Epoch 25: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0025.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5426 - sparse_categorical_accuracy: 0.0877 - val_loss: 7.1034 - val_sparse_categorical_accuracy: 0.0621\n",
            "Epoch 26/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5257 - sparse_categorical_accuracy: 0.0898\n",
            "Epoch 26: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0026.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5257 - sparse_categorical_accuracy: 0.0898 - val_loss: 7.0987 - val_sparse_categorical_accuracy: 0.0663\n",
            "Epoch 27/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.5109 - sparse_categorical_accuracy: 0.0916\n",
            "Epoch 27: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0027.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.5109 - sparse_categorical_accuracy: 0.0916 - val_loss: 7.1017 - val_sparse_categorical_accuracy: 0.0656\n",
            "Epoch 28/300\n",
            "1129/1129 [==============================] - ETA: 0s - loss: 6.4980 - sparse_categorical_accuracy: 0.0929\n",
            "Epoch 28: saving model to ./checkpoints/transfer/P2 - M2 with TL , Embedding, Conv1D and Global Max layers Fine tuned.kerascp-0028.ckpt\n",
            "1129/1129 [==============================] - 30s 26ms/step - loss: 6.4980 - sparse_categorical_accuracy: 0.0929 - val_loss: 7.1231 - val_sparse_categorical_accuracy: 0.0634\n",
            "Epoch 29/300\n",
            " 893/1129 [======================>.......] - ETA: 6s - loss: 6.4831 - sparse_categorical_accuracy: 0.0945"
          ]
        }
      ],
      "source": [
        "# Run code\n",
        "%run part_2/part_2_artist_classification.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4VAv_SgUs2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc637e3-17f6-4999-8477-ac7c3deddd4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'./part_2/multi_label_example.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/multi_label_example.py'\n",
            "'./part_2/part_2_artist_classification.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/part_2_artist_classification.py'\n",
            "'./part_2/part_2_artist_with_transformer.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/part_2_artist_with_transformer.py'\n",
            "'./part_2/part_2_seqtoseq.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/part_2_seqtoseq.py'\n",
            "'./part_2/part_2_transfer_learning.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/part_2_transfer_learning.py'\n",
            "'./part_2/part_2_transformers.py' -> '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3/part_2/part_2_transformers.py'\n"
          ]
        }
      ],
      "source": [
        "#Backup\n",
        "%cp -rv ./part_2 '/gdrive/MyDrive/Data Science - MSC/YEAR2_SEMESTER2/M10_SPEC9993_DEEP_LEARNING/Assignment/COLAB3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7UfPVttVNqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c195fc-7038-4d98-d21f-b338334a7759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive.zip             \u001b[0m\u001b[01;34mdownloaded_embeddings\u001b[0m/      \u001b[01;34mpart_1\u001b[0m/\n",
            "\u001b[01;34mcheckpoints\u001b[0m/            \u001b[01;34mdownloaded_models\u001b[0m/          \u001b[01;34mpart_2\u001b[0m/\n",
            "\u001b[01;34mdatasets\u001b[0m/               \u001b[01;34mfigures\u001b[0m/                    \u001b[01;34m__pycache__\u001b[0m/\n",
            "dl_common_functions.py  glove.6B.zip                \u001b[01;34mresults\u001b[0m/\n",
            "dl_project.part_1.log   part_0_data_preparation.py  saved_models.zip\n"
          ]
        }
      ],
      "source": [
        "%ls ."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "%run part_2/part_2_artist_classification",
      "provenance": [],
      "authorship_tag": "ABX9TyO5zv6a0+VG61zexBHetEoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}